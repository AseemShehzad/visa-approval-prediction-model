{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a14192d8",
   "metadata": {},
   "source": [
    "# Scrape Data\n",
    "\n",
    "1. Import Selenium and BeautifulSoup\n",
    "2. Open Facebook.com and login\n",
    "3. Go the the requested facebook page\n",
    "4. Click all \"See More\" Buttons on the page to show the full text\n",
    "5. Extract all posts from the page using beautifulsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "66b54f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports here\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "483fc43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Specify vairables here ####\n",
    "\n",
    "url = \"https://www.facebook.com/groups/1541028822851688/search/?q=accepted\"\n",
    "# Number of times to scroll down\n",
    "scrolls = 30\n",
    "\n",
    "# Facebook login credentials\n",
    "email = os.environ.get('facebook_email')\n",
    "f_password = os.environ.get('facebook_password')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69cc569f",
   "metadata": {},
   "source": [
    "### Opening Facebook.com and Signing In!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "28b0f728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are logged in!!\n"
     ]
    }
   ],
   "source": [
    "### Ignoring warnings ###\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.facebook.com/\") \n",
    "\n",
    "#target username\n",
    "username = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='email']\")))\n",
    "password = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='pass']\")))\n",
    "\n",
    "#enter username and password\n",
    "username.clear()\n",
    "username.send_keys(email)\n",
    "password.clear()\n",
    "password.send_keys(f_password)\n",
    "\n",
    "#target the login button and click it\n",
    "button = WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[name='login']\"))).click()\n",
    "\n",
    "print(\"We are logged in!!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7e0ae17",
   "metadata": {},
   "source": [
    "### Opening the specified url and scrolling to the end of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4537f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import time\n",
    "\n",
    "# opening the specified url\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "# loop to scroll down and click on \"See more\" buttons until the bottom of the page is reached\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    # Scroll down to the bottom\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Try to find 'See more' buttons and click them\n",
    "    see_more_buttons = driver.find_elements(By.XPATH, \"//div[contains(text(), 'See more')]\")\n",
    "    for button in see_more_buttons:\n",
    "        try:\n",
    "            action = ActionChains(driver)\n",
    "            action.move_to_element(button).perform()\n",
    "            button.click()\n",
    "            time.sleep(.5)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Calculate new scroll height and compare with the last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "12fbbfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scroll to the top of the page\n",
    "driver.execute_script(\"window.scrollTo(document.body.scrollHeight, 0);\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ddc3c69b",
   "metadata": {},
   "source": [
    "### Extract posts using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "46f7509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "all_posts = soup.find_all(\"div\", {\"class\": \"x1yztbdb x1n2onr6 xh8yej3 x1ja2u2z\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "39eeeb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "Skipping post due to error: list index out of range\n",
      "The number of posts extracted: 69\n",
      "The number of posts skipped due to errors: 30\n"
     ]
    }
   ],
   "source": [
    "post_list = []\n",
    "error_count = 0\n",
    "\n",
    "for post in all_posts:\n",
    "    try:\n",
    "        # Extract the text, separating by the specified string.\n",
    "        plain_text = post.get_text(separator=\"\\n\").rsplit(\"Shared with Members of Pakistani Students in USA\")\n",
    "        post_content = plain_text[1].rsplit(\"All reactions\")[0]\n",
    "        post_list.append(post_content)\n",
    "    except Exception as e:\n",
    "        error_count += 1\n",
    "        print(f\"Skipping post due to error: {e}\")\n",
    "\n",
    "print(f\"The number of posts extracted: {len(post_list)}\")\n",
    "print(f\"The number of posts skipped due to errors: {error_count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb8d30ae",
   "metadata": {},
   "source": [
    "### Save the Data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "727e1a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(post_list, columns=['Text'])\n",
    "df.to_csv('data/april_2024/accepted_post_list_2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NeuralNets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
